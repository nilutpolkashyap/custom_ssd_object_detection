{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python starter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV:  4.5.3\n",
      "Numpy:  1.19.5\n"
     ]
    }
   ],
   "source": [
    "from starter import *\n",
    "library_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arduino', 'microbit', 'esp32']\n"
     ]
    }
   ],
   "source": [
    "labels = ['arduino', 'microbit', 'esp32']\n",
    "# labels = ['arduino']\n",
    "number_imgs = 150\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('..', 'ssd_workspace', 'image_dataset', 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    !mkdir {IMAGES_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\ssd_workspace\\\\videos\\\\arduino.mp4', '..\\\\ssd_workspace\\\\videos\\\\microbit.mp4', '..\\\\ssd_workspace\\\\videos\\\\esp32.mp4']\n"
     ]
    }
   ],
   "source": [
    "VIDEOS_PATH = []\n",
    "VIDEOS_PATH.append(os.path.join('..', 'ssd_workspace','videos', 'arduino.mp4'))\n",
    "VIDEOS_PATH.append(os.path.join('..', 'ssd_workspace','videos','microbit.mp4'))\n",
    "VIDEOS_PATH.append(os.path.join('..', 'ssd_workspace','videos','esp32.mp4'))\n",
    "print(VIDEOS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arduino': '..\\\\ssd_workspace\\\\videos\\\\arduino.mp4', 'microbit': '..\\\\ssd_workspace\\\\videos\\\\microbit.mp4', 'esp32': '..\\\\ssd_workspace\\\\videos\\\\esp32.mp4'}\n"
     ]
    }
   ],
   "source": [
    "videos = {}\n",
    "for key in labels:\n",
    "    for value in VIDEOS_PATH:\n",
    "        videos[key] = value\n",
    "        VIDEOS_PATH.remove(value)\n",
    "        break\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for arduino\n",
      "Number of images collected for arduino : 25\n",
      "Collecting images for microbit\n",
      "Number of images collected for microbit : 25\n",
      "Collecting images for esp32\n",
      "Number of images collected for esp32 : 25\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(\"Collecting images for {}\".format(label))\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(videos[label]) \n",
    "\n",
    "        img_num = 0\n",
    "        while(cap.isOpened()):  \n",
    "            ret,frame = cap.read()\n",
    "\n",
    "            cv2.imshow('video',frame)\n",
    "            \"\"\"\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):      #To check if 'q' key is pressed \n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(33) == ord('a'):\n",
    "                print(\"pressed a\")    \"\"\"\n",
    "            if img_num == 25:\n",
    "                print(\"Number of images collected for {} : {}\".format(label, img_num))\n",
    "                break\n",
    "\n",
    "            k = cv2.waitKey(1)\n",
    "            if k & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            if k & 0xFF == ord('a'):\n",
    "                img_name = os.path.join(IMAGES_PATH, label+'_'+'{}.jpg'.format(img_num))\n",
    "                cv2.imwrite(img_name, frame)\n",
    "                img_num = img_num + 1\n",
    "    #             print(\"image saved {}\".format(img_num))\n",
    "\n",
    "            time.sleep(0.05)\n",
    "    except cv2.error as error:\n",
    "        print(\"Video ended\")\n",
    "#         print(\"[Error]: {}\".format(error))\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "current_dir = IMAGES_PATH\n",
    "split_pct = 10;\n",
    "# train_set = os.path.join('..', 'ssd_workspace', 'image_dataset', 'train_test_set')\n",
    "# test_set = os.path.join('..', 'ssd_workspace', 'image_dataset', 'train_test_set')\n",
    "file_train = open(\"train_test_set/train.txt\", \"w\")  \n",
    "file_test = open(\"train_test_set/test.txt\", \"w\")  \n",
    "counter = 1  \n",
    "index_test = round(100 / split_pct)  \n",
    "for pathAndFilename in glob.iglob(os.path.join(current_dir, \"*.jpg\")):  \n",
    "        title, ext = os.path.splitext(os.path.basename(pathAndFilename))\n",
    "        if counter == index_test:\n",
    "                counter = 1\n",
    "                file_test.write(current_dir + \"/\" + title + '.jpg' + \"\\n\")\n",
    "        else:\n",
    "                file_train.write(current_dir + \"/\" + title + '.jpg' + \"\\n\")\n",
    "                counter = counter + 1\n",
    "file_train.close()\n",
    "file_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting image1 / 75 \\ n arduino_0\n",
      "converting image2 / 75 \\ n arduino_1\n",
      "converting image3 / 75 \\ n arduino_10\n",
      "converting image4 / 75 \\ n arduino_11\n",
      "converting image5 / 75 \\ n arduino_12\n",
      "converting image6 / 75 \\ n arduino_13\n",
      "converting image7 / 75 \\ n arduino_14\n",
      "converting image8 / 75 \\ n arduino_15\n",
      "converting image9 / 75 \\ n arduino_16\n",
      "converting image10 / 75 \\ n arduino_17\n",
      "converting image11 / 75 \\ n arduino_18\n",
      "converting image12 / 75 \\ n arduino_19\n",
      "converting image13 / 75 \\ n arduino_2\n",
      "converting image14 / 75 \\ n arduino_20\n",
      "converting image15 / 75 \\ n arduino_21\n",
      "converting image16 / 75 \\ n arduino_22\n",
      "converting image17 / 75 \\ n arduino_23\n",
      "converting image18 / 75 \\ n arduino_24\n",
      "converting image19 / 75 \\ n arduino_3\n",
      "converting image20 / 75 \\ n arduino_4\n",
      "converting image21 / 75 \\ n arduino_5\n",
      "converting image22 / 75 \\ n arduino_6\n",
      "converting image23 / 75 \\ n arduino_7\n",
      "converting image24 / 75 \\ n arduino_8\n",
      "converting image25 / 75 \\ n arduino_9\n",
      "converting image26 / 75 \\ n esp32_0\n",
      "converting image27 / 75 \\ n esp32_1\n",
      "converting image28 / 75 \\ n esp32_10\n",
      "converting image29 / 75 \\ n esp32_11\n",
      "converting image30 / 75 \\ n esp32_12\n",
      "converting image31 / 75 \\ n esp32_13\n",
      "converting image32 / 75 \\ n esp32_14\n",
      "converting image33 / 75 \\ n esp32_15\n",
      "converting image34 / 75 \\ n esp32_16\n",
      "converting image35 / 75 \\ n esp32_17\n",
      "converting image36 / 75 \\ n esp32_18\n",
      "converting image37 / 75 \\ n esp32_19\n",
      "converting image38 / 75 \\ n esp32_2\n",
      "converting image39 / 75 \\ n esp32_20\n",
      "converting image40 / 75 \\ n esp32_21\n",
      "converting image41 / 75 \\ n esp32_22\n",
      "converting image42 / 75 \\ n esp32_23\n",
      "converting image43 / 75 \\ n esp32_24\n",
      "converting image44 / 75 \\ n esp32_3\n",
      "converting image45 / 75 \\ n esp32_4\n",
      "converting image46 / 75 \\ n esp32_5\n",
      "converting image47 / 75 \\ n esp32_6\n",
      "converting image48 / 75 \\ n esp32_7\n",
      "converting image49 / 75 \\ n esp32_8\n",
      "converting image50 / 75 \\ n esp32_9\n",
      "converting image51 / 75 \\ n microbit_0\n",
      "converting image52 / 75 \\ n microbit_1\n",
      "converting image53 / 75 \\ n microbit_10\n",
      "converting image54 / 75 \\ n microbit_11\n",
      "converting image55 / 75 \\ n microbit_12\n",
      "converting image56 / 75 \\ n microbit_13\n",
      "converting image57 / 75 \\ n microbit_14\n",
      "converting image58 / 75 \\ n microbit_15\n",
      "converting image59 / 75 \\ n microbit_16\n",
      "converting image60 / 75 \\ n microbit_17\n",
      "converting image61 / 75 \\ n microbit_18\n",
      "converting image62 / 75 \\ n microbit_19\n",
      "converting image63 / 75 \\ n microbit_2\n",
      "converting image64 / 75 \\ n microbit_20\n",
      "converting image65 / 75 \\ n microbit_21\n",
      "converting image66 / 75 \\ n microbit_22\n",
      "converting image67 / 75 \\ n microbit_23\n",
      "converting image68 / 75 \\ n microbit_24\n",
      "converting image69 / 75 \\ n microbit_3\n",
      "converting image70 / 75 \\ n microbit_4\n",
      "converting image71 / 75 \\ n microbit_5\n",
      "converting image72 / 75 \\ n microbit_6\n",
      "converting image73 / 75 \\ n microbit_7\n",
      "converting image74 / 75 \\ n microbit_8\n",
      "converting image75 / 75 \\ n microbit_9\n",
      "\n",
      "Finished converting the Pascal VOC dataset!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\tf_object_detection\\tf-gpu-venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#import xml.etree.elementtree as et\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "#There are only two definitions of my tags, depending on my own pictures\n",
    "VOC_LABELS = {\n",
    "    'none': (0, 'Background'),\n",
    "    'arduino': (1, 'arduino'),\n",
    "    'microbit': (2, 'microbit'),\n",
    "    'esp32': (2, 'esp32'),\n",
    "}\n",
    "\n",
    "#A folder for pictures and labels\n",
    "DIRECTORY_ANNOTATIONS = 'F:/github/ssd_workspace/image_dataset/annotations/'\n",
    "DIRECTORY_IMAGES = 'F:/github/ssd_workspace/image_dataset/images/'\n",
    "\n",
    "#Random seed\n",
    "RANDOM_SEED = 4242\n",
    "SAMPLES_PER_FILES = 1 #samples per file\n",
    "\n",
    "\n",
    "#Generate integer, floating point, and string properties\n",
    "def int64_feature(value):\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "#Image processing\n",
    "def _process_image(directory, name):\n",
    "    # Read the image file.\n",
    "    filename = directory + DIRECTORY_IMAGES + name + '.jpg'\n",
    "    image_data = tf.io.gfile.GFile(filename, 'rb').read()\n",
    "\n",
    "    # Read the XML annotation file.\n",
    "    filename = os.path.join(directory, DIRECTORY_ANNOTATIONS, name + '.xml')\n",
    "    tree = et.parse(filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Image shape.\n",
    "    size = root.find('size')\n",
    "    shape = [int(size.find('height').text),\n",
    "             int(size.find('width').text),\n",
    "             int(size.find('depth').text)]\n",
    "    # Find annotations.\n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    labels_text = []\n",
    "    difficult = []\n",
    "    truncated = []\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        labels.append(int(VOC_LABELS[label][0]))\n",
    "        labels_text.append (label.encode ('ascii')) #ාchange to ASCII format\n",
    "\n",
    "        if obj.find('difficult'):\n",
    "            difficult.append(int(obj.find('difficult').text))\n",
    "        else:\n",
    "            difficult.append(0)\n",
    "        if obj.find('truncated'):\n",
    "            truncated.append(int(obj.find('truncated').text))\n",
    "        else:\n",
    "            truncated.append(0)\n",
    "\n",
    "        bbox = obj.find('bndbox')\n",
    "\n",
    "        ####################################################################\t\t\n",
    "        bboxes.append((max(float(bbox.find('ymin').text) / shape[0],0.0),\n",
    "                   max(float(bbox.find('xmin').text) / shape[1],0.0),\n",
    "                   min(float(bbox.find('ymax').text) / shape[0],1.0),\n",
    "                   min(float(bbox.find('xmax').text) / shape[1],1.0)\n",
    "                   ))\n",
    "        ######################################################################\n",
    "        # the above code in ### replaced by below commented code\n",
    "        # a = float(bbox.find('ymin').text) / shape[0]\n",
    "        # b = float(bbox.find('xmin').text) / shape[1]\n",
    "        # a1 = float(bbox.find('ymax').text) / shape[0]\n",
    "        # b1 = float(bbox.find('xmax').text) / shape[1]\n",
    "        # a_e = a1 - a\n",
    "        # b_e = b1 - b\n",
    "        # if abs(a_e) < 1 and abs(b_e) < 1:\n",
    "            # bboxes.append((a, b, a1, b1))\n",
    "\n",
    "    return image_data, shape, bboxes, labels, labels_text, difficult, truncated\n",
    "\n",
    "\n",
    "#Conversion example\n",
    "def _convert_to_example(image_data, labels, labels_text, bboxes, shape,\n",
    "                        difficult, truncated):\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    for b in bboxes:\n",
    "        assert len(b) == 4\n",
    "        # pylint: disable=expression-not-assigned\n",
    "        [l.append(point) for l, point in zip([ymin, xmin, ymax, xmax], b)]\n",
    "        # pylint: enable=expression-not-assigned\n",
    "\n",
    "    image_format = b'JPEG'\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': int64_feature(shape[0]),\n",
    "        'image/width': int64_feature(shape[1]),\n",
    "        'image/channels': int64_feature(shape[2]),\n",
    "        'image/shape': int64_feature(shape),\n",
    "        'image/object/bbox/xmin': float_feature(xmin),\n",
    "        'image/object/bbox/xmax': float_feature(xmax),\n",
    "        'image/object/bbox/ymin': float_feature(ymin),\n",
    "        'image/object/bbox/ymax': float_feature(ymax),\n",
    "        'image/object/bbox/label': int64_feature(labels),\n",
    "        'image/object/bbox/label_text': bytes_feature(labels_text),\n",
    "        'image/object/bbox/difficult': int64_feature(difficult),\n",
    "        'image/object/bbox/truncated': int64_feature(truncated),\n",
    "        'image/format': bytes_feature(image_format),\n",
    "        'image/encoded': bytes_feature(image_data)}))\n",
    "    return example\n",
    "\n",
    "\n",
    "#Add to tfrecord\n",
    "def _add_to_tfrecord(dataset_dir, name, tfrecord_writer):\n",
    "    image_data, shape, bboxes, labels, labels_text, difficult, truncated = \\\n",
    "        _process_image(dataset_dir, name)\n",
    "    example = _convert_to_example(image_data, labels, labels_text,\n",
    "                                  bboxes, shape, difficult, truncated)\n",
    "    tfrecord_writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "#Name is the prefix of the converted file\n",
    "def _get_output_filename(output_dir, name, idx):\n",
    "    return '%s/%s_%03d.tfrecord' % (output_dir, name, idx)\n",
    "\n",
    "\n",
    "def run(dataset_dir, output_dir, name='voc_train', shuffling=False):\n",
    "    if not tf.io.gfile.exists(dataset_dir):\n",
    "        tf.io.gfile.makedirs(dataset_dir)\n",
    "\n",
    "    path = os.path.join(dataset_dir, DIRECTORY_ANNOTATIONS)\n",
    "    filenames = sorted (os.listdir (path)) #(sort)\n",
    "    if shuffling:\n",
    "        random.seed(RANDOM_SEED)\n",
    "        random.shuffle(filenames)\n",
    "\n",
    "    i = 0\n",
    "    fidx = 0\n",
    "    while i < len(filenames):\n",
    "        # Open new TFRecord file.\n",
    "        tf_filename = _get_output_filename(output_dir, name, fidx)\n",
    "        with tf.io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
    "            j = 0\n",
    "            while i < len(filenames) and j < SAMPLES_PER_FILES:\n",
    "                sys.stdout.write ('converting image%d /% d \\ n '% (i + 1, len (filenames))) #(terminal printing, similar to print)\n",
    "                sys.stdout.flush() #(buffer)\n",
    "\n",
    "                filename = filenames[i]\n",
    "                img_name = filename[:-4]\n",
    "                print(img_name)\n",
    "                _add_to_tfrecord(dataset_dir, img_name, tfrecord_writer)\n",
    "                i += 1\n",
    "                j += 1\n",
    "            fidx += 1\n",
    "\n",
    "    print('\\nFinished converting the Pascal VOC dataset!')\n",
    "\n",
    "\n",
    "#Original dataset path, output path and output file name\n",
    "dataset_dir = \"\"   #\"/voc2007/\"\n",
    "output_dir = \"../ssd_workspace/tfrecords/\"\n",
    "name = \"voc_2007_train\"\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    run(dataset_dir, output_dir, name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-venv",
   "language": "python",
   "name": "tf-gpu-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
